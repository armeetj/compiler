block_1:
    movq free_ptr(%rip), %r11
    addq $32, free_ptr(%rip)
    movq $7, 0(%r11)
    movq %r11, -16(%r15)
    movq $6, 8(%r11)
    movq $0, %rcx
    movq -16(%r15), %r11
    movq $7, 16(%r11)
    movq $0, %rcx
    movq -16(%r15), %r11
    movq $0, 24(%r11)
    movq $0, %rcx
    movq $1, %rdi
    movq $2, %rsi
    movq $3, %rdx
    movq $1, %rcx
    movq $5, %r8
    movq -16(%r15), %r9
    callq *-8(%rbp)
    movq %rax, -16(%rbp)
    movq $1, %rcx
    movq $1, -8(%rbp)
    addq $21, -8(%rbp)
    addq -8(%rbp), %rcx
    movq -16(%rbp), %rax
    movq %rax, -8(%rbp)
    addq %rcx, -8(%rbp)
    movq -152(%rbp), %rcx
    addq -8(%rbp), %rcx
    movq -144(%rbp), %rax
    movq %rax, -8(%rbp)
    addq %rcx, -8(%rbp)
    movq -136(%rbp), %rcx
    addq -8(%rbp), %rcx
    movq -128(%rbp), %rax
    movq %rax, -8(%rbp)
    addq %rcx, -8(%rbp)
    movq -120(%rbp), %rcx
    addq -8(%rbp), %rcx
    movq -112(%rbp), %rax
    movq %rax, -8(%rbp)
    addq %rcx, -8(%rbp)
    movq -104(%rbp), %rcx
    addq -8(%rbp), %rcx
    movq -96(%rbp), %rax
    movq %rax, -8(%rbp)
    addq %rcx, -8(%rbp)
    movq -88(%rbp), %rcx
    addq -8(%rbp), %rcx
    movq -80(%rbp), %rax
    movq %rax, -8(%rbp)
    addq %rcx, -8(%rbp)
    movq -72(%rbp), %rcx
    addq -8(%rbp), %rcx
    movq -64(%rbp), %rax
    movq %rax, -8(%rbp)
    addq %rcx, -8(%rbp)
    movq -56(%rbp), %rcx
    addq -8(%rbp), %rcx
    movq -48(%rbp), %rax
    movq %rax, -8(%rbp)
    addq %rcx, -8(%rbp)
    movq -40(%rbp), %rcx
    addq -8(%rbp), %rcx
    movq -32(%rbp), %rax
    movq %rax, -8(%rbp)
    addq %rcx, -8(%rbp)
    movq -24(%rbp), %rcx
    addq -8(%rbp), %rcx
    movq -8(%r15), %rax
    addq %rcx, %rax
    jmp main_conclusion

block_2:
    movq $0, %rcx
    jmp block_1

block_3:
    movq %r15, %rdi
    movq $32, %rsi
    callq collect
    jmp block_1

block_4:
    movq free_ptr(%rip), %r11
    addq $48, free_ptr(%rip)
    movq $11, 0(%r11)
    movq %r11, -8(%r15)
    movq $6, 8(%r11)
    movq $0, %rcx
    movq -8(%r15), %r11
    movq $7, 16(%r11)
    movq $0, %rcx
    movq -8(%r15), %r11
    movq $8, 24(%r11)
    movq $0, %rcx
    movq -8(%r15), %r11
    movq $9, 32(%r11)
    movq $0, %rcx
    movq -8(%r15), %r11
    movq $1, 40(%r11)
    movq $0, %rcx
    movq $1, %rdi
    movq $2, %rsi
    movq $3, %rdx
    movq $0, %rcx
    movq $5, %r8
    movq -8(%r15), %r9
    callq *-8(%rbp)
    movq %rax, -8(%r15)
    movq $1, -24(%rbp)
    movq $1, -32(%rbp)
    movq $1, -40(%rbp)
    movq $1, -48(%rbp)
    movq $1, -56(%rbp)
    movq $1, -64(%rbp)
    movq $1, -72(%rbp)
    movq $1, -80(%rbp)
    movq $1, -88(%rbp)
    movq $1, -96(%rbp)
    movq $1, -104(%rbp)
    movq $1, -112(%rbp)
    movq $1, -120(%rbp)
    movq $1, -128(%rbp)
    movq $1, -136(%rbp)
    movq $1, -144(%rbp)
    movq $1, -152(%rbp)
    leaq big2(%rip), %rax
    movq %rax, -8(%rbp)
    movq free_ptr(%rip), %rcx
    addq $32, %rcx
    movq fromspace_end(%rip), %rax
    movq %rax, -16(%rbp)
    cmpq -16(%rbp), %rcx
    jl block_2
    jmp block_3

block_5:
    movq $0, %rcx
    jmp block_4

block_6:
    movq %r15, %rdi
    movq $48, %rsi
    callq collect
    jmp block_4

main_start:
    leaq big(%rip), %rax
    movq %rax, -8(%rbp)
    movq free_ptr(%rip), %rcx
    addq $48, %rcx
    movq fromspace_end(%rip), %rax
    movq %rax, -8(%r15)
    cmpq -8(%r15), %rcx
    jl block_5
    jmp block_6

    .globl main
    .align 8

main:
    pushq %rbp
    movq %rsp, %rbp
    subq $160, %rsp
    movq $65536, %rdi
    movq $65536, %rsi
    callq initialize
    movq rootstack_begin(%rip), %r15
    movq $0, 0(%r15)
    movq $0, 8(%r15)
    addq $16, %r15
    jmp main_start

main_conclusion:
    subq $16, %r15
    addq $160, %rsp
    popq %rbp
    retq

big_start:
    movq %rdi, -8(%rbp)
    movq %rsi, -8(%rbp)
    movq %rdx, -8(%rbp)
    movq %rcx, -8(%rbp)
    movq %r8, %rcx
    movq %r9, %rcx
    movq %rcx, %r11
    movq 40(%r11), %rcx
    movq -8(%rbp), %rax
    addq %rcx, %rax
    jmp big_conclusion

    .globl big
    .align 8

big:
    pushq %rbp
    movq %rsp, %rbp
    subq $16, %rsp
    jmp big_start

big_conclusion:
    addq $16, %rsp
    popq %rbp
    retq

big2_start:
    movq %rdi, -8(%rbp)
    movq %rsi, -8(%rbp)
    movq %rdx, -8(%rbp)
    movq %rcx, -8(%rbp)
    movq %r8, %rcx
    movq %r9, %rcx
    movq %rcx, %r11
    movq 24(%r11), %rcx
    movq -8(%rbp), %rax
    addq %rcx, %rax
    jmp big2_conclusion

    .globl big2
    .align 8

big2:
    pushq %rbp
    movq %rsp, %rbp
    subq $16, %rsp
    jmp big2_start

big2_conclusion:
    addq $16, %rsp
    popq %rbp
    retq
